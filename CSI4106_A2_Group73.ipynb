{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woofbonjour/4106_Ass2/blob/main/CSI4106_A2_Group73.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ASSIGNMENT 2 CONTENT BELOW\n"
      ],
      "metadata": {
        "id": "9KRufkcY7dF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group Description**\n",
        "\n",
        "Group Number: 73 \\\\\n",
        "Member Names: Sabeeha Ahamed, Megan van Zyl \\\\\n",
        "Member Student Numbers: 300167378, 300397712 \\\\"
      ],
      "metadata": {
        "id": "f2Eeke4Z_EkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Classification Empirical Study**\n",
        "\n",
        "The goal of this study is to develop classifiers and document the analysis of the results. Two classification algorithm will be explored: Naive Bayes and Logistic Regression. These classifiers will be trained on real data and be evaluated on their predictions.\n",
        "\n",
        "The dataset we have chosen for this assignment is the data collected from a study conducted on maternal health risk. It has collected data on various paitents including Age, Systolic Blood Pressure, Diastolic Blood Pressure, Blood Sugar, Body Temperature, Heart Rate and Risk Level. These have been collected to better understand how the different factors affect the maternal mortality.\n",
        "\n",
        "This dataset contains six features and the target of the classifiers would be to predict the risk level. The features are the attributes mentioned above. The risk level can be one of these three: high, medium, and low. Therefore, it has three classes. This dataset has no missing values.\n",
        "\n",
        "For more information on the dataset: https://archive.ics.uci.edu/dataset/863/maternal+health+risk."
      ],
      "metadata": {
        "id": "ze_MtQW0gO49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Feature Engineering**\n",
        "\n",
        "The dataset has six attributes that are used to determine the risk level of the patient. There is no missing data. We do not have the medical expertise or background to determine if all of the six features affect the risk level.\n",
        "\n",
        "Some ways to figure out if there are attributes that have no impact on the risk level:\n",
        "1. Consult with medical professionals or domain experts.\n",
        "2. Create a scatter plot with all the values to see a visual represntation of patterns and association of the attributes.\n",
        "3. Carry out correlation analysis of each attribute or use different statistical tests to analyze the attributes..\n",
        "4. Try different combinations of attributes to see how they affect the risk level.\n",
        "\n",
        "Since the dataset is taken from a published study conducted by a professional in the field, we will conduct our study with the assumption that all attibutes are equally important.\n",
        "\n",
        "All of the attrbiutes are continuous features. Below lists the ranges of each based on the dataset:\n",
        "- Age ranges from 10-70\n",
        "- SystolicBP ranges from 70-160\n",
        "- DiastolicBP ranges from 49-100\n",
        "- Blood Sugar ranges from 6.0-19.0\n",
        "- Body Temp ranges from 98-103\n",
        "- Heart rate ranges from 7-90\n",
        "\n",
        "Normalization of attributes often help improve performances of the algorithms. However, that is only the case when the ranges present are varied. The ranges of each attribute in this case is close to each other and there is no indication that normalizing them would have an impact on the performance. In fact, if we were to normalize, it might have the opposite effect. It could decrease the significance of the result. Therefore, we will not be normalizing the attributes."
      ],
      "metadata": {
        "id": "uD0ulKKuyhoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "The dataset is a csv file with 1013 entries. Each entry in the dataset is an input given to the algorithm to train and test it. It consists of seven elements:\n",
        "1. An integer corresponding to the age.\n",
        "2. An integer corresponding to the SystolicBP.\n",
        "3. An integer corresponding to the DiastolicBP.\n",
        "4. A float corresponding to the Blood Suger (BS).\n",
        "5. An integer corresponding to the BodyTemp.\n",
        "6. An integer corresponding to the HeartRate.\n",
        "7. The expected risk level is based on the six previous attributes."
      ],
      "metadata": {
        "id": "C8vwHE0G_iOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import important libraries**"
      ],
      "metadata": {
        "id": "OZTWy1qN2BzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "GmP1buROhaOx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Dataset**\n",
        "\n",
        "Link provided below to dataset from github:"
      ],
      "metadata": {
        "id": "wNJyoeCz00Kr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "BrhpM-HwhaOy"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/woofbonjour/4106_Ass2/main/Maternal%20Health%20Risk%20Data%20Set.csv'\n",
        "\n",
        "dataset = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns of the dataset:"
      ],
      "metadata": {
        "id": "4Drc71BY2a7w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGxZXmhNhaOz",
        "outputId": "1744a091-e7f6-4286-eadc-16e1e30983ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate',\n",
              "       'RiskLevel'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we expected, we have columns for age, systolicBP, diastolicBP, bodyTemp, heartRate, and riskLevel for all the instances."
      ],
      "metadata": {
        "id": "aNZaqcCT2w-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see the first 10 entries (rows):"
      ],
      "metadata": {
        "id": "jkokOHRj2kgZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0xqfPrBEhaOz",
        "outputId": "7edf7a1d-54e2-4c01-9f9f-795e6cbb7300"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  SystolicBP  DiastolicBP     BS  BodyTemp  HeartRate  RiskLevel\n",
              "0   25         130           80  15.00      98.0         86  high risk\n",
              "1   35         140           90  13.00      98.0         70  high risk\n",
              "2   29          90           70   8.00     100.0         80  high risk\n",
              "3   30         140           85   7.00      98.0         70  high risk\n",
              "4   35         120           60   6.10      98.0         76   low risk\n",
              "5   23         140           80   7.01      98.0         70  high risk\n",
              "6   23         130           70   7.01      98.0         78   mid risk\n",
              "7   35          85           60  11.00     102.0         86  high risk\n",
              "8   32         120           90   6.90      98.0         70   mid risk\n",
              "9   42         130           80  18.00      98.0         70  high risk"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8be92c6-c532-42c7-8e55-44ac02d31808\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>15.00</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>13.00</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>8.00</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>140</td>\n",
              "      <td>85</td>\n",
              "      <td>7.00</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.10</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>low risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>23</td>\n",
              "      <td>140</td>\n",
              "      <td>80</td>\n",
              "      <td>7.01</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>23</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>7.01</td>\n",
              "      <td>98.0</td>\n",
              "      <td>78</td>\n",
              "      <td>mid risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35</td>\n",
              "      <td>85</td>\n",
              "      <td>60</td>\n",
              "      <td>11.00</td>\n",
              "      <td>102.0</td>\n",
              "      <td>86</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>32</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>6.90</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>mid risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>18.00</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8be92c6-c532-42c7-8e55-44ac02d31808')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8be92c6-c532-42c7-8e55-44ac02d31808 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8be92c6-c532-42c7-8e55-44ac02d31808');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cbc27643-3522-46e5-a77b-05836dea9a2a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cbc27643-3522-46e5-a77b-05836dea9a2a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cbc27643-3522-46e5-a77b-05836dea9a2a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ],
      "source": [
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Step**\n",
        "\n",
        "Convert the coloumns into lists. It's possible that certain rows in the dataset contain empty values in specific columns. We also aim to eliminate these rows as they do not provide any useful information. We use dropna() function to do so:"
      ],
      "metadata": {
        "id": "CP1nkMb27A4n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "LT_iYgxhhaO0"
      },
      "outputs": [],
      "source": [
        "#Ignore the warning messages.\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "dataset.Age = dataset.Age.tolist()\n",
        "dataset.SystolicBP = dataset.SystolicBP.tolist()\n",
        "dataset.DiastolicBP = dataset.DiastolicBP.tolist()\n",
        "dataset.BS = dataset.BS.tolist()\n",
        "dataset.BodyTemp = dataset.BodyTemp.tolist()\n",
        "dataset.HeartRate = dataset.HeartRate.tolist()\n",
        "dataset.RiskLevel = dataset.RiskLevel.tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Encoding Features**\n",
        "\n",
        "As you will use models that need discrete or continuous attributes, think about data\n",
        "encoding and transformation."
      ],
      "metadata": {
        "id": "QSvRaKv3DQss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression:**\n",
        "\n",
        "This classifier expects continuous attributes. Since all of our attributes are continuous, there is no need to carry out encoding or tranformation techniques."
      ],
      "metadata": {
        "id": "klrZp2CkDhK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes:**\n",
        "\n",
        "This classifier expects discrete attributes. CategoricalNB and GaussianNB are two of several classifiers in scikitlearn. CategoricalNB expects discrete attributes whereas GaussianNB expects continuous attributes. The attributes need to be transformed/discretized in order to use CategoricalNB. There would be no need for transformation when using GaussianNB.\n"
      ],
      "metadata": {
        "id": "pc30I0ciDrjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Classifier Models**\n",
        "\n",
        "Below are the two classifier algorithms.\n"
      ],
      "metadata": {
        "id": "0ER3-7di7ufy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression**"
      ],
      "metadata": {
        "id": "2Jv3o5Gb0ap8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_reg(dataset):\n",
        "  #initialize the features\n",
        "  x_prescale = dataset[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "\n",
        "  #initialize the target\n",
        "  y = dataset['RiskLevel']\n",
        "\n",
        "  # Fit scaler to the feature data\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x_prescale)\n",
        "\n",
        "  # Train model\n",
        "  model = LogisticRegression(random_state=0)\n",
        "  model.fit(x, y)\n",
        "  y_pred = model.predict(x)\n",
        "\n",
        "  # Compute the accuracy\n",
        "  accuracy = accuracy_score(y_pred, y)\n",
        "\n",
        "  return accuracy, model"
      ],
      "metadata": {
        "id": "20E33A7x0jDE"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, model = logistic_reg(dataset)\n",
        "\n",
        "print(\"The accuracy is: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYQGS5UB5hnc",
        "outputId": "60a9f13c-2513-4e32-a766-09aa5ba363b1"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is:  0.6242603550295858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "# # Assuming you have defined X and y\n",
        "# x_prescale = dataset[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "# y = dataset['RiskLevel']\n",
        "\n",
        "# # Convert class labels to integers\n",
        "# class_mapping = {label: idx for idx, label in enumerate(np.unique(y))}\n",
        "# y = np.array([class_mapping[label] for label in y])\n",
        "\n",
        "# # Select two features to visualize (e.g., 'Age' and 'SystolicBP')\n",
        "# selected_features = ['Age', 'SystolicBP']\n",
        "\n",
        "# # Get the corresponding columns from x_prescale\n",
        "# x_prescale_subset = x_prescale[selected_features]\n",
        "\n",
        "# # Fit scaler to the selected feature data\n",
        "# scaler = StandardScaler()\n",
        "# x_subset = scaler.fit_transform(x_prescale_subset)\n",
        "\n",
        "# # Train model\n",
        "# model = LogisticRegression(random_state=0)\n",
        "# model.fit(x_subset, y)\n",
        "\n",
        "# # Predict the class labels\n",
        "# y_pred = model.predict(x_subset)\n",
        "\n",
        "# # Compute the accuracy\n",
        "# accuracy = accuracy_score(y_pred, y)\n",
        "\n",
        "# print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# # Create a pair plot to visualize the decision boundaries\n",
        "# plot_decision_regions(X=x_subset, y=y, clf=model, legend=2)\n",
        "\n",
        "# # Add axis labels and plot title\n",
        "# plt.xlabel(selected_features[0])\n",
        "# plt.ylabel(selected_features[1])\n",
        "# plt.title(\"Logistic Regression Decision Boundaries\")\n",
        "\n",
        "# # Show the plot\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "_HikCVqpC1xw"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# # Assuming you have X with three categories and Y with one category\n",
        "\n",
        "# # Create a 3D scatter plot\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# # Define colors for each category in X\n",
        "# colors = ['r', 'g', 'b']\n",
        "\n",
        "# # Assign a symbol to the single category in Y\n",
        "# symbol = 'o'  # You can choose any marker symbol you prefer\n",
        "\n",
        "# # Loop through the data points in X\n",
        "# for category, color in enumerate(colors):\n",
        "#     indices = X == category\n",
        "#     ax.scatter(X[indices], Y[indices], 0, c=color, label=f'Category {category}')\n",
        "\n",
        "# # Plot the single category in Y\n",
        "# ax.scatter(X[Y == 1], Y[Y == 1], 0, c='k', marker=symbol, label='Category Y')\n",
        "\n",
        "# # Set axis labels\n",
        "# ax.set_xlabel('X')\n",
        "# ax.set_ylabel('Y')\n",
        "\n",
        "# # Add a legend\n",
        "# ax.legend()\n",
        "\n",
        "# # Set\n"
      ],
      "metadata": {
        "id": "gbY4Tq-zQ-hs"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "kG2P17rD0TVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_gaussian(dataset):\n",
        "  #initialize the features\n",
        "  x = dataset[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "\n",
        "  #initialize the target\n",
        "  y = dataset['RiskLevel']\n",
        "\n",
        "  # Train model\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=250)\n",
        "\n",
        "  model = GaussianNB()\n",
        "  model.fit(x,y)\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  # Compute the accuracy\n",
        "  accuracy = accuracy_score(y_pred, y_test)\n",
        "\n",
        "  return accuracy, model\n"
      ],
      "metadata": {
        "id": "FNTMjCFy3gpA"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, model = naive_bayes_gaussian(dataset)\n",
        "\n",
        "print(\"The accuracy is: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8KlAj5sCrlc",
        "outputId": "8d62c723-7446-4991-cf9a-8e6d07c723f3"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is:  0.6470588235294118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Train and Evaluate Model**\n",
        "\n",
        "Carry out 4-fold cross validation for training the model.\n",
        "\n",
        "Perform an evaluation with precision/recall measures."
      ],
      "metadata": {
        "id": "fPzEh_735Uzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "VZ9M2VQwcTzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_reg_kfold(dataset, model):\n",
        "  #initialize the features\n",
        "  x_prescale = dataset[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "\n",
        "  #initialize the target\n",
        "  y = dataset['RiskLevel']\n",
        "\n",
        "  # Fit scaler to the feature data\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x_prescale)\n",
        "\n",
        "  # Perform kfold cross validation\n",
        "  kf = KFold(n_splits=4, shuffle=True, random_state=200)\n",
        "  y_pred = cross_val_predict(model, x, y, cv=kf)\n",
        "\n",
        "  report = classification_report(y, y_pred, labels=['high risk', 'low risk', 'mid risk'])\n",
        "\n",
        "  # Format the results\n",
        "\n",
        "  from sklearn.metrics import precision_score,recall_score\n",
        "  precisionMicro = format(precision_score(y, y_pred, average='micro'),\".2f\")\n",
        "  precisionMacro = format(precision_score(y, y_pred, average='macro'),\".2f\")\n",
        "  recallMicro = format(recall_score(y, y_pred, average='micro'),\".2f\")\n",
        "  recallMacro = format(recall_score(y, y_pred, average='macro'),\".2f\")\n",
        "\n",
        "  return report, precisionMicro, precisionMacro, recallMicro, recallMacro"
      ],
      "metadata": {
        "id": "Ij5a-0-4cdUc"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, model = logistic_reg(dataset)\n",
        "report_l, precisionMicro_l, precisionMacro_l, recallMicro_l, recallMacro_l = logistic_reg_kfold(dataset,model)\n",
        "\n",
        "print(report_l)\n",
        "print(\"Precision Macro: \", precisionMacro_l)\n",
        "print(\"Precision Micro: \", precisionMicro_l)\n",
        "print(\"Recall Macro: \\t \", recallMacro_l)\n",
        "print(\"Recall Micro: \\t \", recallMicro_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNRmmYFz-erZ",
        "outputId": "dcafe92b-4e83-4d53-d41a-67d3875682d3"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high risk       0.74      0.71      0.73       272\n",
            "    low risk       0.63      0.77      0.70       406\n",
            "    mid risk       0.45      0.35      0.40       336\n",
            "\n",
            "    accuracy                           0.62      1014\n",
            "   macro avg       0.61      0.61      0.61      1014\n",
            "weighted avg       0.60      0.62      0.60      1014\n",
            "\n",
            "Precision Macro:  0.61\n",
            "Precision Micro:  0.62\n",
            "Recall Macro: \t  0.61\n",
            "Recall Micro: \t  0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "lqHGY-Ya5_C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_gaussian_kfold(dataset,model):\n",
        "\n",
        "  #initialize the features\n",
        "  x = dataset[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "\n",
        "  #initialize the target\n",
        "  y = dataset['RiskLevel']\n",
        "\n",
        "  # Perform k fold\n",
        "  kf = KFold(n_splits=4, shuffle=True, random_state=300)\n",
        "  y_pred = cross_val_predict(model, x, y, cv=kf)\n",
        "  #scores = cross_val_score(model, x, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "  report = classification_report(y, y_pred, labels=['high risk', 'low risk', 'mid risk'])\n",
        "\n",
        "  # Format results\n",
        "  #print(round(f1_score(y, y_pred, average='macro'),2))\n",
        "  #print(format(f1_score(y, y_pred, average='micro'),\".2f\"))\n",
        "  from sklearn.metrics import precision_score,recall_score\n",
        "  precisionMicro = format(precision_score(y, y_pred, average='micro'),\".2f\")\n",
        "  precisionMacro = format(precision_score(y, y_pred, average='macro'),\".2f\")\n",
        "  recallMicro = format(recall_score(y, y_pred, average='micro'),\".2f\")\n",
        "  recallMacro = format(recall_score(y, y_pred, average='macro'),\".2f\")\n",
        "  #print(round(precision_score(y, y_pred, average='macro'),2))\n",
        "  #print(round(precision_score(y, y_pred, average='micro'),2))\n",
        "  #print(format(recall_score(y, y_pred, average='macro'),\".2f\"))\n",
        "  #print(format(recall_score(y, y_pred, average='micro'),\".2f\"))\n",
        "\n",
        "  return report, precisionMicro, precisionMacro, recallMicro, recallMacro\n"
      ],
      "metadata": {
        "id": "-PUqF6hr5UbA"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_n, precisionMicro_n, precisionMacro_n, recallMicro_n, recallMacro_n = naive_bayes_gaussian_kfold(dataset,model)\n",
        "\n",
        "#print(\"Average accuracy: \", accuracy.mean())\n",
        "print(report_n)\n",
        "print(precisionMacro_n)\n",
        "print(precisionMicro_n)\n",
        "print(recallMacro_n)\n",
        "print(recallMicro_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHCq76go8NYf",
        "outputId": "797e6e48-d842-4d8b-9e73-daac2c88fb0b"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high risk       0.81      0.64      0.71       272\n",
            "    low risk       0.57      0.76      0.65       406\n",
            "    mid risk       0.46      0.36      0.40       336\n",
            "\n",
            "    accuracy                           0.59      1014\n",
            "   macro avg       0.61      0.59      0.59      1014\n",
            "weighted avg       0.60      0.59      0.59      1014\n",
            "\n",
            "0.61\n",
            "0.59\n",
            "0.59\n",
            "0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**\n",
        "\n",
        "1. Precision vs Recall\n",
        "\n",
        "The differences between the results for two models (shown below) are minor.\n",
        "\n",
        "*Precision* measures the accuracy of the results (true positives / true positive + true negatives).\n",
        "\n",
        "*Recall* measures the completeness of the results (true positives / true positive + false negatives).\n",
        "\n",
        "Recall is generally considered the more import of the two as\n",
        "\n",
        "2. Macro vs Micro\n",
        "\n",
        "*Macro-averages* consider each class seperately, and calculate the average precision/recall value individually before taking a global average.\n",
        "\n",
        "i.e. precision macro = sum of precision for each class / number of classes\n",
        "\n",
        "\n",
        "*Micro-averages* on the other hand will take the average precision/recall value across all classes at once. This means classes with more data will be weighted heavier.\n",
        "\n",
        "ie. precision micro = sum of true positives across all classes / sum of true positives + false positives across all classes\n",
        "\n",
        "In other words, macro-averages analyse the accuracy of each class equally which will help show which classes the model is better at distinguishing. While the micro-averages analyse how accurate the model is across all classes, which will help indicate if there is a class imbalance."
      ],
      "metadata": {
        "id": "r6cp2xkBQg4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic regression - Naive Bayes Gaussian \\n\")\n",
        "print(\"Precision Macro: \", round(float(precisionMicro_l)-float(precisionMicro_n), 2))\n",
        "print(\"Precision Micro: \", round(float(precisionMacro_l)-float(precisionMacro_n), 2))\n",
        "print(\"Recall Macro: \\t \", round(float(recallMacro_l)-float(recallMacro_n), 2))\n",
        "print(\"Recall Micro: \\t \", round(float(recallMicro_l)-float(recallMicro_n), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0-bIsyTQggz",
        "outputId": "664a45a8-9c1f-4841-b802-4bc323b75c26"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression - Naive Bayes Gaussian \n",
            "\n",
            "Precision Macro:  0.03\n",
            "Precision Micro:  0.0\n",
            "Recall Macro: \t  0.02\n",
            "Recall Micro: \t  0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Balance\n",
        "\n"
      ],
      "metadata": {
        "id": "l0_md7X8uWep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the last column into a separate array\n",
        "class_labels = dataset.iloc[:, -1]\n",
        "# Initialize a dictionary to store class counts\n",
        "class_counts = {}\n",
        "\n",
        "# Count the occurrences of each class\n",
        "for label in class_labels:\n",
        "    if label in class_counts:\n",
        "        class_counts[label] += 1\n",
        "    else:\n",
        "        class_counts[label] = 1\n",
        "\n",
        "# Print the class counts\n",
        "for class_label, count in class_counts.items():\n",
        "    print(f\"Class {class_label}: {count} occurrences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CssD0rR6s4cW",
        "outputId": "ffd046f3-e068-4b70-c5cf-69036c13c29a"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class high risk: 272 occurrences\n",
            "Class low risk: 406 occurrences\n",
            "Class mid risk: 336 occurrences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Modify Parameters**\n",
        "\n",
        "Modify parameters in the function."
      ],
      "metadata": {
        "id": "uYLcoZUYWThA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "1tClkDD1XblC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MgR-CLgUXfQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**\n",
        "\n",
        "The parameter that will be changed is the smoothing factor."
      ],
      "metadata": {
        "id": "XByNBlvgXfyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_gaussian_smoothing_factor(dataset):\n",
        "\n",
        "  #initialize the features\n",
        "  x = dataset[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "\n",
        "  #initialize the target\n",
        "  y = dataset['RiskLevel']\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=250)\n",
        "\n",
        "  model = GaussianNB(var_smoothing = 1)\n",
        "\n",
        "  kf = KFold(n_splits=4, shuffle=True, random_state=300)\n",
        "  y_pred = cross_val_predict(model, x, y, cv=kf)\n",
        "  #scores = cross_val_score(model, x, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "  report = classification_report(y, y_pred, labels=['high risk', 'low risk', 'mid risk'])\n",
        "\n",
        "  return report"
      ],
      "metadata": {
        "id": "PoS7VEzkXq8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = naive_bayes_gaussian_smoothing_factor(dataset)\n",
        "\n",
        "#print(\"Average accuracy: \", accuracy.mean())\n",
        "print(report)"
      ],
      "metadata": {
        "id": "UCW5l_H_YThc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "5rQYdUQx-dGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Analysis**"
      ],
      "metadata": {
        "id": "9YITaqOgaka1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "4Ypp7TpkAIUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Conclusion**\n",
        "\n"
      ],
      "metadata": {
        "id": "8Ikmq-si_23Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "41s8gvCNABDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9 References**\n",
        "\n"
      ],
      "metadata": {
        "id": "PtbOgI1q_9a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hint:** To share a link to your colab notebook, click on \"share\" on the top right. Then, under *General access* , change *Restricted* to \"Anyone with the link\"."
      ],
      "metadata": {
        "id": "zF9cuDJqF75q"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}